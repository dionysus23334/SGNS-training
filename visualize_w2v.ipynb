{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb1032c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 放到一个单元格里（或替换你的脚本）---\n",
    "import os, argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "def pca_reduce(X, n_components=2):\n",
    "    Xc = X - X.mean(axis=0, keepdims=True)\n",
    "    U, S, Vt = np.linalg.svd(Xc, full_matrices=False)\n",
    "    return Xc @ Vt[:n_components].T\n",
    "\n",
    "def try_tsne(X, n_components=2, perplexity=30, random_state=42):\n",
    "    try:\n",
    "        from sklearn.manifold import TSNE\n",
    "        Z = TSNE(n_components=n_components, init=\"random\",\n",
    "                 perplexity=perplexity, random_state=random_state,\n",
    "                 learning_rate=\"auto\").fit_transform(X)\n",
    "        return Z, True\n",
    "    except Exception:\n",
    "        return pca_reduce(X, n_components=n_components), False\n",
    "\n",
    "def collect_subset(wv, seed_words, nn_per_seed=15, limit=300):\n",
    "    chosen, seen = [], set()\n",
    "    seeds = [w for w in seed_words if w in wv]\n",
    "    for s in seeds:\n",
    "        if s not in seen:\n",
    "            chosen.append(s); seen.add(s)\n",
    "        for w, _ in wv.most_similar(s, topn=nn_per_seed):\n",
    "            if w not in seen:\n",
    "                chosen.append(w); seen.add(w)\n",
    "            if len(chosen) >= limit: break\n",
    "        if len(chosen) >= limit: break\n",
    "    if len(chosen) < limit:\n",
    "        for w in wv.index_to_key:\n",
    "            if w not in seen:\n",
    "                chosen.append(w); seen.add(w)\n",
    "            if len(chosen) >= limit: break\n",
    "    return chosen\n",
    "\n",
    "def plot_2d(words, coords, out_path):\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    x, y = coords[:,0], coords[:,1]\n",
    "    plt.scatter(x, y, s=12)\n",
    "    for i, w in enumerate(words):\n",
    "        if i % max(1, len(words)//200) == 0:\n",
    "            plt.annotate(w, (x[i], y[i]), fontsize=8, alpha=0.8)\n",
    "    plt.title(\"Word Embeddings (2D projection)\")\n",
    "    plt.tight_layout(); os.makedirs(\"outputs\", exist_ok=True)\n",
    "    plt.savefig(out_path, dpi=200); plt.close()\n",
    "    print(\"✅ Saved 2D →\", out_path)\n",
    "\n",
    "def plot_3d(words, coords, out_path):\n",
    "    from mpl_toolkits.mplot3d import Axes3D  # noqa\n",
    "    fig = plt.figure(figsize=(12, 9))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    xs, ys, zs = coords[:,0], coords[:,1], coords[:,2]\n",
    "    ax.scatter(xs, ys, zs, s=12)\n",
    "    step = max(1, len(words)//200)\n",
    "    for i, w in enumerate(words[::step]):\n",
    "        j = i*step; ax.text(xs[j], ys[j], zs[j], w, fontsize=7)\n",
    "    ax.set_title(\"Word Embeddings (3D projection)\")\n",
    "    plt.tight_layout(); os.makedirs(\"outputs\", exist_ok=True)\n",
    "    plt.savefig(out_path, dpi=200); plt.close()\n",
    "    print(\"✅ Saved 3D →\", out_path)\n",
    "\n",
    "def visualize(vec=\"outputs/w2v_text8_sgns.vec\", limit=300, nn_per_seed=15, method=\"pca\"):\n",
    "    wv = KeyedVectors.load_word2vec_format(vec, binary=False)\n",
    "    print(\"Loaded:\", len(wv.key_to_index), \"dim:\", wv.vector_size)\n",
    "    seed_words = [\"king\",\"queen\",\"man\",\"woman\",\"london\",\"paris\",\"france\",\"england\",\n",
    "                  \"computer\",\"software\",\"data\",\"science\",\"music\",\"art\",\"city\",\"country\",\"river\",\"mountain\"]\n",
    "    words = collect_subset(wv, seed_words, nn_per_seed=nn_per_seed, limit=limit)\n",
    "    X = np.stack([wv[w] for w in words], axis=0)\n",
    "\n",
    "    if method == \"tsne\":\n",
    "        Z2, used = try_tsne(X, n_components=2)\n",
    "        print(\"Using\", \"t-SNE(2D)\" if used else \"PCA(2D)\")\n",
    "    else:\n",
    "        Z2 = pca_reduce(X, n_components=2); print(\"Using PCA(2D)\")\n",
    "    plot_2d(words, Z2, \"outputs/emb_2d.png\")\n",
    "\n",
    "    if method == \"tsne\":\n",
    "        Z3, used = try_tsne(X, n_components=3)\n",
    "        print(\"Using\", \"t-SNE(3D)\" if used else \"PCA(3D)\")\n",
    "    else:\n",
    "        Z3 = pca_reduce(X, n_components=3); print(\"Using PCA(3D)\")\n",
    "    plot_3d(words, Z3, \"outputs/emb_3d.png\")\n",
    "\n",
    "# —— 在Jupyter里直接调用：\n",
    "# visualize(method=\"pca\")        # 默认PCA\n",
    "# visualize(method=\"tsne\")       # 若已安装scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c07ef40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 71290 dim: 300\n",
      "Using PCA(2D)\n",
      "✅ Saved 2D → outputs/emb_2d.png\n",
      "Using PCA(3D)\n",
      "✅ Saved 3D → outputs/emb_3d.png\n"
     ]
    }
   ],
   "source": [
    "visualize(method=\"pca\", limit=300)\n",
    "# 或\n",
    "# visualize(method=\"tsne\", limit=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62b5abfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Word2Vec 复评可视化（多模型对比，统一投影） ====\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# ---------- 基础降维 ----------\n",
    "def pca_fit_on_concat(X_list, n_components=2):\n",
    "    \"\"\"在多个矩阵的拼接上拟合同一套 PCA 主轴；返回 (mean, Vt[:n])\"\"\"\n",
    "    X = np.vstack(X_list)\n",
    "    mu = X.mean(axis=0, keepdims=True)\n",
    "    Xc = X - mu\n",
    "    U, S, Vt = np.linalg.svd(Xc, full_matrices=False)\n",
    "    return mu, Vt[:n_components]  # components_\n",
    "\n",
    "def pca_transform(X, mean, components):\n",
    "    return (X - mean) @ components.T\n",
    "\n",
    "def pca_reduce(X, n_components=2):\n",
    "    Xc = X - X.mean(axis=0, keepdims=True)\n",
    "    U, S, Vt = np.linalg.svd(Xc, full_matrices=False)\n",
    "    return Xc @ Vt[:n_components].T\n",
    "\n",
    "def try_tsne(X, n_components=2, perplexity=30, random_state=42):\n",
    "    \"\"\"仅作单模型可视化；多模型对比请用 PCA\"\"\"\n",
    "    try:\n",
    "        from sklearn.manifold import TSNE\n",
    "        Z = TSNE(n_components=n_components, init=\"random\",\n",
    "                 perplexity=perplexity, random_state=random_state,\n",
    "                 learning_rate=\"auto\").fit_transform(X)\n",
    "        return Z, True\n",
    "    except Exception:\n",
    "        return pca_reduce(X, n_components=n_components), False\n",
    "\n",
    "# ---------- 采样子集（确保各模型可比：使用“公共词集合”） ----------\n",
    "def collect_subset_common(wv_list, seed_words, nn_per_seed=15, limit=300):\n",
    "    \"\"\"\n",
    "    先用第一个模型的近邻引导主题，再取所有模型的公共词，保证同一批词在所有模型中均存在。\n",
    "    \"\"\"\n",
    "    base = wv_list[0]\n",
    "    seeds = [w for w in seed_words if w in base]\n",
    "    chosen = []\n",
    "    seen = set()\n",
    "    for s in seeds:\n",
    "        if s not in seen:\n",
    "            chosen.append(s); seen.add(s)\n",
    "        for w, _ in base.most_similar(s, topn=nn_per_seed):\n",
    "            if w not in seen:\n",
    "                chosen.append(w); seen.add(w)\n",
    "            if len(chosen) >= limit:\n",
    "                break\n",
    "        if len(chosen) >= limit:\n",
    "            break\n",
    "    # 若不足，补高频词\n",
    "    if len(chosen) < limit:\n",
    "        for w in base.index_to_key:\n",
    "            if w not in seen:\n",
    "                chosen.append(w); seen.add(w)\n",
    "            if len(chosen) >= limit:\n",
    "                break\n",
    "    # 取所有模型的交集\n",
    "    common = []\n",
    "    for w in chosen:\n",
    "        if all(w in wv for wv in wv_list):\n",
    "            common.append(w)\n",
    "    # 兜底：若交集仍太少，直接用所有模型的整体交集高频前 limit 个\n",
    "    if len(common) < min(50, limit//2):\n",
    "        sets = [set(wv.index_to_key) for wv in wv_list]\n",
    "        inter = sets[0]\n",
    "        for s in sets[1:]:\n",
    "            inter = inter & s\n",
    "        # 按第一个模型的词频顺序截取\n",
    "        common = [w for w in wv_list[0].index_to_key if w in inter][:limit]\n",
    "    return common[:limit]\n",
    "\n",
    "# ---------- 绘图 ----------\n",
    "def overlay_2d(words, coords_list, labels, out_path):\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    for i, Z in enumerate(coords_list):\n",
    "        x, y = Z[:,0], Z[:,1]\n",
    "        plt.scatter(x, y, s=12, label=labels[i], alpha=0.7)\n",
    "    # 标注少量词避免过密：仅标注 seed-like 的“代表词”\n",
    "    for w in words[:max(20, len(words)//20)]:\n",
    "        idx = words.index(w)\n",
    "        # 用第一组坐标放标签\n",
    "        x, y = coords_list[0][idx,0], coords_list[0][idx,1]\n",
    "        plt.annotate(w, (x, y), fontsize=7, alpha=0.8)\n",
    "    plt.legend()\n",
    "    plt.title(\"Word Embeddings (2D overlay, shared PCA basis)\")\n",
    "    plt.tight_layout(); os.makedirs(\"outputs\", exist_ok=True)\n",
    "    plt.savefig(out_path, dpi=200); plt.close()\n",
    "    print(\"✅ Saved 2D overlay →\", out_path)\n",
    "\n",
    "def overlay_3d(words, coords_list, labels, out_path):\n",
    "    from mpl_toolkits.mplot3d import Axes3D  # noqa\n",
    "    fig = plt.figure(figsize=(12, 9))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    for i, Z in enumerate(coords_list):\n",
    "        xs, ys, zs = Z[:,0], Z[:,1], Z[:,2]\n",
    "        ax.scatter(xs, ys, zs, s=12, alpha=0.7, label=labels[i])\n",
    "    # 只用第一组坐标标一部分标签\n",
    "    step = max(1, len(words)//100)\n",
    "    for i, w in enumerate(words[::step]):\n",
    "        j = i*step\n",
    "        x, y, z = coords_list[0][j,0], coords_list[0][j,1], coords_list[0][j,2]\n",
    "        ax.text(x, y, z, w, fontsize=7)\n",
    "    ax.legend()\n",
    "    ax.set_title(\"Word Embeddings (3D overlay, shared PCA basis)\")\n",
    "    plt.tight_layout(); os.makedirs(\"outputs\", exist_ok=True)\n",
    "    plt.savefig(out_path, dpi=200); plt.close()\n",
    "    print(\"✅ Saved 3D overlay →\", out_path)\n",
    "\n",
    "# ---------- 单模型旧版接口（保持兼容） ----------\n",
    "def visualize(vec=\"outputs/w2v_text8_sgns.vec\", limit=300, nn_per_seed=15, method=\"pca\"):\n",
    "    wv = KeyedVectors.load_word2vec_format(vec, binary=False)\n",
    "    print(\"Loaded:\", len(wv.key_to_index), \"dim:\", wv.vector_size)\n",
    "    seed_words = [\"king\",\"queen\",\"man\",\"woman\",\"london\",\"paris\",\"france\",\"england\",\n",
    "                  \"computer\",\"software\",\"data\",\"science\",\"music\",\"art\",\"city\",\"country\",\"river\",\"mountain\"]\n",
    "    words = collect_subset_common([wv], seed_words, nn_per_seed=nn_per_seed, limit=limit)\n",
    "    X = np.stack([wv[w] for w in words], axis=0)\n",
    "\n",
    "    if method == \"tsne\":\n",
    "        Z2, used = try_tsne(X, n_components=2); print(\"Using\", \"t-SNE(2D)\" if used else \"PCA(2D)\")\n",
    "        Z3, used = try_tsne(X, n_components=3); print(\"Using\", \"t-SNE(3D)\" if used else \"PCA(3D)\")\n",
    "    else:\n",
    "        Z2 = pca_reduce(X, n_components=2); print(\"Using PCA(2D)\")\n",
    "        Z3 = pca_reduce(X, n_components=3); print(\"Using PCA(3D)\")\n",
    "\n",
    "    os.makedirs(\"outputs\", exist_ok=True)\n",
    "    # 单模型也用 overlay 画法（一个图层）\n",
    "    overlay_2d(words, [Z2], [Path(vec).name], \"outputs/emb_2d.png\")\n",
    "    overlay_3d(words, [Z3], [Path(vec).name], \"outputs/emb_3d.png\")\n",
    "\n",
    "# ---------- 新增：多模型对比（共享投影；推荐 method='pca'） ----------\n",
    "def visualize_compare(vec_paths, labels=None, limit=300, nn_per_seed=15, method=\"pca\"):\n",
    "    vec_paths = [p for p in vec_paths if Path(p).exists()]\n",
    "    assert len(vec_paths) >= 2, \"至少传入两个已存在的 .vec 路径用于对比\"\n",
    "    if labels is None:\n",
    "        labels = [Path(p).stem for p in vec_paths]\n",
    "    else:\n",
    "        assert len(labels) == len(vec_paths), \"labels 数量需与 vec_paths 一致\"\n",
    "\n",
    "    # 加载\n",
    "    wvs = [KeyedVectors.load_word2vec_format(p, binary=False) for p in vec_paths]\n",
    "    print(\"Loaded models:\", [f\"{Path(p).name}(|V|={len(wv.key_to_index)},D={wv.vector_size})\"\n",
    "                            for p, wv in zip(vec_paths, wvs)])\n",
    "\n",
    "    # 公共词集合（确保可比）\n",
    "    seed_words = [\"king\",\"queen\",\"man\",\"woman\",\"london\",\"paris\",\"france\",\"england\",\n",
    "                  \"computer\",\"software\",\"data\",\"science\",\"music\",\"art\",\"city\",\"country\",\"river\",\"mountain\"]\n",
    "    words = collect_subset_common(wvs, seed_words, nn_per_seed=nn_per_seed, limit=limit)\n",
    "    print(f\"Using common word subset: {len(words)} items\")\n",
    "\n",
    "    # 取向量\n",
    "    X_list = [np.stack([wv[w] for w in words], axis=0) for wv in wvs]\n",
    "\n",
    "    # 统一投影\n",
    "    if method == \"tsne\":\n",
    "        print(\"⚠️ t-SNE 无法共享坐标轴，不适合严格对比；将分别降维并叠加，仅作参考。\")\n",
    "        Z2_list, Z3_list = [], []\n",
    "        for X in X_list:\n",
    "            Z2, _ = try_tsne(X, n_components=2); Z2_list.append(Z2)\n",
    "            Z3, _ = try_tsne(X, n_components=3); Z3_list.append(Z3)\n",
    "    else:\n",
    "        # PCA 在所有模型的拼接上拟合同一套主轴\n",
    "        mu2, comps2 = pca_fit_on_concat([X for X in X_list], n_components=2)\n",
    "        mu3, comps3 = pca_fit_on_concat([X for X in X_list], n_components=3)\n",
    "        Z2_list = [pca_transform(X, mu2, comps2) for X in X_list]\n",
    "        Z3_list = [pca_transform(X, mu3, comps3) for X in X_list]\n",
    "\n",
    "    # 绘图（叠加）\n",
    "    os.makedirs(\"outputs\", exist_ok=True)\n",
    "    overlay_2d(words, Z2_list, labels, \"outputs/emb_compare_2d.png\")\n",
    "    overlay_3d(words, Z3_list, labels, \"outputs/emb_compare_3d.png\")\n",
    "\n",
    "# ===== 调用示例 =====\n",
    "# 单模型（保持你原来的接口）：\n",
    "# visualize(method=\"pca\", limit=300)\n",
    "\n",
    "# 多模型对比（推荐；共享 PCA 主轴）：\n",
    "# visualize_compare(\n",
    "#     vec_paths=[\n",
    "#         \"outputs/w2v_text8_sgns.vec\",\n",
    "#         \"outputs/w2v_text8_sgns_abtt.vec\",\n",
    "#         # \"outputs/w2v_text8_sgns_cn.vec\",\n",
    "#     ],\n",
    "#     labels=[\"raw\",\"abtt\"],   # 可自定义\n",
    "#     method=\"pca\",\n",
    "#     limit=300,\n",
    "#     nn_per_seed=15,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "044c18bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded models: ['w2v_text8_sgns.vec(|V|=71290,D=300)', 'w2v_text8_sgns_abtt.vec(|V|=71290,D=300)']\n",
      "Using common word subset: 300 items\n",
      "✅ Saved 2D overlay → outputs/emb_compare_2d.png\n",
      "✅ Saved 3D overlay → outputs/emb_compare_3d.png\n"
     ]
    }
   ],
   "source": [
    "visualize_compare(\n",
    "    vec_paths=[\n",
    "        \"outputs/w2v_text8_sgns.vec\",\n",
    "        \"outputs/w2v_text8_sgns_abtt.vec\",\n",
    "        # \"outputs/w2v_text8_sgns_cn.vec\",\n",
    "    ],\n",
    "    labels=[\"raw\",\"abtt\"],\n",
    "    method=\"pca\",       # 对比请用 PCA\n",
    "    limit=300,\n",
    "    nn_per_seed=15,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w2v_sgns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
